{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[KeOps] Warning : There were warnings or errors :\n",
      "/bin/sh: brew: command not found\n",
      "\n",
      "[KeOps] Warning : CUDA libraries not found or could not be loaded; Switching to CPU only.\n",
      "\n",
      "[KeOps] Warning : There were warnings or errors :\n",
      "/bin/sh: brew: command not found\n",
      "\n",
      "[KeOps] Warning : OpenMP library not found, it must be downloaded through Homebrew for apple Silicon chips\n",
      "[KeOps] Warning : OpenMP support is not available. Disabling OpenMP.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import ot\n",
    "from scipy.sparse import coo_matrix\n",
    "import time\n",
    "import psutil\n",
    "import os\n",
    "import gc\n",
    "\n",
    "def get_memory_mb():\n",
    "    \"\"\"Get current process memory usage in MB\"\"\"\n",
    "    process = psutil.Process(os.getpid())\n",
    "    return process.memory_info().rss / 1024 / 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## Test: Identity Transport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparse edges: 1,000 (density=0.10%)\n"
     ]
    }
   ],
   "source": [
    "n = 1000\n",
    "\n",
    "a = np.ones(n) / n\n",
    "b = np.ones(n) / n\n",
    "\n",
    "rows = np.arange(n)\n",
    "cols = np.arange(n)\n",
    "data = np.ones(n) \n",
    "M_sparse = coo_matrix((data, (rows, cols)), shape=(n, n))\n",
    "\n",
    "large_cost = 1e6\n",
    "M_dense = np.full((n, n), large_cost)\n",
    "np.fill_diagonal(M_dense, 1)\n",
    "\n",
    "print(f\"Sparse edges: {M_sparse.nnz:,} (density={100*M_sparse.nnz/(n*n):.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dense solver:\n",
      "  Cost: 1.0000000000\n",
      "  Time: 23.2 ms\n",
      "  Memory: +11.70 MB (before: 723.6 MB, after: 735.3 MB)\n",
      "  Result: OPTIMAL\n",
      "  Flow on diagonal: 1.000000 (expected: 1.0)\n",
      "  Flow off diagonal: -0.0000000000 (expected: 0.0)\n",
      "Sparse solver:\n",
      "  Cost: 1.0000000000\n",
      "  Time: 0.5 ms\n",
      "  Memory: +0.14 MB (before: 735.3 MB, after: 735.4 MB)\n",
      "  Result: OPTIMAL\n",
      "\n",
      "Cost difference: 0.00e+00\n",
      "SUCCESS: Dense and sparse give identical results!\n",
      "   Speedup: 46.84x\n",
      "   Memory savings: 11.56 MB\n"
     ]
    }
   ],
   "source": [
    "print(\"Dense solver:\")\n",
    "mem_before = get_memory_mb()\n",
    "t0 = time.perf_counter()\n",
    "G_dense, log_dense = ot.emd(a, b, M_dense, log=True)\n",
    "t_dense = time.perf_counter() - t0\n",
    "mem_after = get_memory_mb()\n",
    "mem_dense = mem_after - mem_before\n",
    "\n",
    "print(f\"  Cost: {log_dense['cost']:.10f}\")\n",
    "print(f\"  Time: {t_dense*1000:.1f} ms\")\n",
    "print(f\"  Memory: {mem_dense:+.2f} MB (before: {mem_before:.1f} MB, after: {mem_after:.1f} MB)\")\n",
    "print(f\"  Result: {log_dense['warning'] or 'OPTIMAL'}\")\n",
    "print(f\"  Flow on diagonal: {np.sum(np.diag(G_dense)):.6f} (expected: 1.0)\")\n",
    "print(f\"  Flow off diagonal: {np.sum(G_dense) - np.sum(np.diag(G_dense)):.10f} (expected: 0.0)\")\n",
    "\n",
    "print(\"Sparse solver:\")\n",
    "mem_before = get_memory_mb()\n",
    "t0 = time.perf_counter()\n",
    "G_sparse, log_sparse = ot.emd(a, b, M_sparse, log=True)\n",
    "t_sparse = time.perf_counter() - t0\n",
    "mem_after = get_memory_mb()\n",
    "mem_sparse = mem_after - mem_before\n",
    "\n",
    "print(f\"  Cost: {log_sparse['cost']:.10f}\")\n",
    "print(f\"  Time: {t_sparse*1000:.1f} ms\")\n",
    "print(f\"  Memory: {mem_sparse:+.2f} MB (before: {mem_before:.1f} MB, after: {mem_after:.1f} MB)\")\n",
    "print(f\"  Result: {log_sparse['warning'] or 'OPTIMAL'}\")\n",
    "if G_sparse is not None:\n",
    "    print(f\"  Flow on diagonal: {np.sum(np.diag(G_sparse)):.6f} (expected: 1.0)\")\n",
    "print()\n",
    "\n",
    "if log_dense['warning'] is None and log_sparse['warning'] is None:\n",
    "    diff = abs(log_dense['cost'] - log_sparse['cost'])\n",
    "    print(f\"Cost difference: {diff:.2e}\")\n",
    "    if diff < 1e-6:\n",
    "        print(\"SUCCESS: Dense and sparse give identical results!\")\n",
    "        print(f\"   Speedup: {t_dense/t_sparse:.2f}x\")\n",
    "        print(f\"   Memory savings: {mem_dense - mem_sparse:.2f} MB\")\n",
    "    else:\n",
    "        print(f\"FAILURE: Costs differ by {diff}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## Test : Circular "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparse edges: 50,000 (density=0.01%)\n"
     ]
    }
   ],
   "source": [
    "n = 25000\n",
    "\n",
    "a = np.ones(n) / n\n",
    "b = np.ones(n) / n\n",
    "\n",
    "rows = []\n",
    "cols = []\n",
    "data = []\n",
    "\n",
    "for i in range(n):\n",
    "    rows.append(i)\n",
    "    cols.append(i)\n",
    "    data.append(1.0)\n",
    "    \n",
    "    rows.append(i)\n",
    "    cols.append((i + 1) % n)\n",
    "    data.append(1.0)\n",
    "\n",
    "M_sparse = coo_matrix((data, (rows, cols)), shape=(n, n))\n",
    "\n",
    "large_cost = 1e6\n",
    "M_dense = np.full((n, n), large_cost)\n",
    "for i in range(n):\n",
    "    M_dense[i, i] = 1.0\n",
    "    M_dense[i, (i + 1) % n] = 1.0\n",
    "\n",
    "print(f\"Sparse edges: {M_sparse.nnz:,} (density={100*M_sparse.nnz/(n*n):.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dense solver:\n",
      "  Cost: 1.0000000000\n",
      "  Time: 61141.4 ms\n",
      "  Memory: -643.88 MB (before: 1346.3 MB, after: 702.4 MB)\n",
      "  Result: OPTIMAL\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print(\"Dense solver:\")\n",
    "mem_before = get_memory_mb()\n",
    "t0 = time.perf_counter()\n",
    "G_dense, log_dense = ot.emd(a, b, M_dense, log=True)\n",
    "t_dense = time.perf_counter() - t0\n",
    "mem_after = get_memory_mb()\n",
    "mem_dense = mem_after - mem_before\n",
    "\n",
    "print(f\"  Cost: {log_dense['cost']:.10f}\")\n",
    "print(f\"  Time: {t_dense*1000:.1f} ms\")\n",
    "print(f\"  Memory: {mem_dense:+.2f} MB (before: {mem_before:.1f} MB, after: {mem_after:.1f} MB)\")\n",
    "print(f\"  Result: {log_dense['warning'] or 'OPTIMAL'}\")\n",
    "del G_dense, M_dense\n",
    "gc.collect()\n",
    "gc.collect()\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4eec7870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparse solver:\n",
      "  Cost: 1.0000000000\n",
      "  Time: 8.7 ms\n",
      "  Memory: +15.53 MB (before: 607.4 MB, after: 623.0 MB)\n",
      "  Result: OPTIMAL\n",
      "\n",
      "Cost difference: 0.00e+00\n",
      "   SUCCESS: Dense and sparse give identical results!\n",
      "   Speedup: 7046.38x\n",
      "   Memory savings: -659.41 MB\n"
     ]
    }
   ],
   "source": [
    "print(\"Sparse solver:\")\n",
    "mem_before = get_memory_mb()\n",
    "t0 = time.perf_counter()\n",
    "G_sparse, log_sparse = ot.emd(a, b, M_sparse, log=True)\n",
    "t_sparse = time.perf_counter() - t0\n",
    "mem_after = get_memory_mb()\n",
    "mem_sparse = mem_after - mem_before\n",
    "\n",
    "print(f\"  Cost: {log_sparse['cost']:.10f}\")\n",
    "print(f\"  Time: {t_sparse*1000:.1f} ms\")\n",
    "print(f\"  Memory: {mem_sparse:+.2f} MB (before: {mem_before:.1f} MB, after: {mem_after:.1f} MB)\")\n",
    "print(f\"  Result: {log_sparse['warning'] or 'OPTIMAL'}\")\n",
    "print()\n",
    "\n",
    "if log_dense['warning'] is None and log_sparse['warning'] is None:\n",
    "    diff = abs(log_dense['cost'] - log_sparse['cost'])\n",
    "    print(f\"Cost difference: {diff:.2e}\")\n",
    "    if diff < 1e-6:\n",
    "        print(\"   SUCCESS: Dense and sparse give identical results!\")\n",
    "        print(f\"   Speedup: {t_dense/t_sparse:.2f}x\")\n",
    "        print(f\"   Memory savings: {mem_dense - mem_sparse:.2f} MB\")\n",
    "    else:\n",
    "        print(f\"    FAILURE: Costs differ by {diff}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## Test 3: Random Sparse Bipartite\n",
    "\n",
    "**Problem**: n sources, n targets, random sparse edges.\n",
    "\n",
    "**Setup**:\n",
    "- Each source connects to k random targets\n",
    "- Every target has at least one incoming edge (guaranteed by construction)\n",
    "\n",
    "**Feasibility**: NOT guaranteed!\n",
    "- Connectivity is necessary but NOT sufficient\n",
    "- With k=20 and uniform distributions, it's VERY LIKELY feasible\n",
    "- But flow bottlenecks could theoretically still occur\n",
    "- If infeasible, we'll see it in the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cell-9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test 3: Random Sparse Bipartite (n=500, k=20)\n",
      "======================================================================\n",
      "Sparse edges: 10,298 (density=4.12%)\n",
      "Edges per source: avg=20.6\n",
      "Sources with edges: 500/500\n",
      "Targets reachable: 500/500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n = 500\n",
    "k = 20  # Each source connects to k random targets\n",
    "np.random.seed(42)\n",
    "\n",
    "print(f\"\\nTest 3: Random Sparse Bipartite (n={n}, k={k})\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Uniform distributions\n",
    "a = np.ones(n) / n\n",
    "b = np.ones(n) / n\n",
    "\n",
    "# Create random sparse graph: ensure every target is reachable\n",
    "rows = []\n",
    "cols = []\n",
    "data = []\n",
    "\n",
    "# First, ensure every target is connected to at least one source\n",
    "for j in range(n):\n",
    "    i = np.random.randint(0, n)\n",
    "    cost = np.random.uniform(0.1, 1.0)\n",
    "    rows.append(i)\n",
    "    cols.append(j)\n",
    "    data.append(cost)\n",
    "\n",
    "# Then add random edges for each source\n",
    "for i in range(n):\n",
    "    # Pick k random targets\n",
    "    targets = np.random.choice(n, size=k, replace=True)\n",
    "    for j in targets:\n",
    "        cost = np.random.uniform(0.1, 1.0)\n",
    "        rows.append(i)\n",
    "        cols.append(j)\n",
    "        data.append(cost)\n",
    "\n",
    "M_sparse = coo_matrix((data, (rows, cols)), shape=(n, n))\n",
    "M_sparse.sum_duplicates()  # Combine duplicate edges\n",
    "\n",
    "# Create dense matrix\n",
    "large_cost = 1e6\n",
    "M_dense = np.full((n, n), large_cost)\n",
    "M_sparse_array = M_sparse.toarray()\n",
    "M_dense[M_sparse_array > 0] = M_sparse_array[M_sparse_array > 0]\n",
    "\n",
    "print(f\"Sparse edges: {M_sparse.nnz:,} (density={100*M_sparse.nnz/(n*n):.2f}%)\")\n",
    "print(f\"Edges per source: avg={M_sparse.nnz/n:.1f}\")\n",
    "\n",
    "# Check connectivity\n",
    "from scipy.sparse import csr_matrix\n",
    "M_csr = csr_matrix(M_sparse)\n",
    "rows_with_edges = (M_csr.getnnz(axis=1) > 0).sum()\n",
    "cols_with_edges = (M_csr.getnnz(axis=0) > 0).sum()\n",
    "print(f\"Sources with edges: {rows_with_edges}/{n}\")\n",
    "print(f\"Targets reachable: {cols_with_edges}/{n}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cell-10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dense solver:\n",
      "  Cost: 0.1676211637\n",
      "  Time: 13.2 ms\n",
      "  Memory: +2.14 MB (before: 631.8 MB, after: 634.0 MB)\n",
      "  Result: OPTIMAL\n",
      "\n",
      "Sparse solver:\n",
      "  Cost: 0.1676211637\n",
      "  Time: 2.3 ms\n",
      "  Memory: +0.55 MB (before: 634.0 MB, after: 634.5 MB)\n",
      "  Result: OPTIMAL\n",
      "\n",
      "Dense cost:  0.1676211637\n",
      "Sparse cost: 0.1676211637\n",
      "Difference: 0.00e+00 (0.000000%)\n",
      "\n",
      "✅ SUCCESS: Dense and sparse give identical results!\n",
      "   Speedup: 5.70x\n",
      "   Memory savings: 1.59 MB\n"
     ]
    }
   ],
   "source": [
    "# Solve with dense\n",
    "print(\"Dense solver:\")\n",
    "mem_before = get_memory_mb()\n",
    "t0 = time.perf_counter()\n",
    "G_dense, log_dense = ot.emd(a, b, M_dense, log=True)\n",
    "t_dense = time.perf_counter() - t0\n",
    "mem_after = get_memory_mb()\n",
    "mem_dense = mem_after - mem_before\n",
    "\n",
    "print(f\"  Cost: {log_dense['cost']:.10f}\")\n",
    "print(f\"  Time: {t_dense*1000:.1f} ms\")\n",
    "print(f\"  Memory: {mem_dense:+.2f} MB (before: {mem_before:.1f} MB, after: {mem_after:.1f} MB)\")\n",
    "print(f\"  Result: {log_dense['warning'] or 'OPTIMAL'}\")\n",
    "print()\n",
    "\n",
    "# Solve with sparse\n",
    "print(\"Sparse solver:\")\n",
    "mem_before = get_memory_mb()\n",
    "t0 = time.perf_counter()\n",
    "G_sparse, log_sparse = ot.emd(a, b, M_sparse, log=True)\n",
    "t_sparse = time.perf_counter() - t0\n",
    "mem_after = get_memory_mb()\n",
    "mem_sparse = mem_after - mem_before\n",
    "\n",
    "print(f\"  Cost: {log_sparse['cost']:.10f}\")\n",
    "print(f\"  Time: {t_sparse*1000:.1f} ms\")\n",
    "print(f\"  Memory: {mem_sparse:+.2f} MB (before: {mem_before:.1f} MB, after: {mem_after:.1f} MB)\")\n",
    "print(f\"  Result: {log_sparse['warning'] or 'OPTIMAL'}\")\n",
    "print()\n",
    "\n",
    "# Compare\n",
    "if log_dense['warning'] is None and log_sparse['warning'] is None:\n",
    "    diff = abs(log_dense['cost'] - log_sparse['cost'])\n",
    "    rel_err = diff / log_dense['cost'] * 100 if log_dense['cost'] > 0 else 0\n",
    "    \n",
    "    print(f\"Dense cost:  {log_dense['cost']:.10f}\")\n",
    "    print(f\"Sparse cost: {log_sparse['cost']:.10f}\")\n",
    "    print(f\"Difference: {diff:.2e} ({rel_err:.6f}%)\")\n",
    "    print()\n",
    "    \n",
    "    if diff < 1e-6:\n",
    "        print(\"✅ SUCCESS: Dense and sparse give identical results!\")\n",
    "        print(f\"   Speedup: {t_dense/t_sparse:.2f}x\")\n",
    "        print(f\"   Memory savings: {mem_dense - mem_sparse:.2f} MB\")\n",
    "    elif rel_err < 0.01:\n",
    "        print(\"✅ PASS: Results match within numerical precision\")\n",
    "        print(f\"   Speedup: {t_dense/t_sparse:.2f}x\")\n",
    "        print(f\"   Memory savings: {mem_dense - mem_sparse:.2f} MB\")\n",
    "    else:\n",
    "        print(f\"❌ FAILURE: Costs differ by {rel_err:.4f}%\")\n",
    "else:\n",
    "    print(f\"❌ FAILURE: One solver failed\")\n",
    "    if log_dense['warning']:\n",
    "        print(f\"   Dense: {log_dense['warning']}\")\n",
    "    if log_sparse['warning']:\n",
    "        print(f\"   Sparse: {log_sparse['warning']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
